{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1VeEWlp0sw8Yhg9gU-vL1CGZJRZmKC3r3",
      "authorship_tag": "ABX9TyNTVjLQ8CN7AyxkPfWOXtEY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anna-alt/AI-Lab/blob/main/SceneRecognition1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HNQjwXsFev0q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler, ConcatDataset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision import models\n",
        "\n",
        "import numpy as np\n",
        "import sklearn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RL-3nOXgBiT",
        "outputId": "d58d4c56-aa9b-4d4d-d2c0-cd8891fdb67c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset_size = 5000\n",
        "val_size = 500\n",
        "num_epochs = 10\n",
        "image_size = (224,224)\n"
      ],
      "metadata": {
        "id": "6LzXm9mDgp4B"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3iFl3W0riYVK",
        "outputId": "dc1e5a5a-593d-4586-bf3f-ed1f43657ab3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Resize(image_size),\n",
        "                              \n",
        "                              ])\n",
        "# Download and load the training data\n",
        "trainset = datasets.SUN397('/content/drive/MyDrive/Data', download= False, transform=transform)\n",
        "splittrain = torch.utils.data.random_split(trainset, [trainset_size, len(trainset) - trainset_size])[0]\n",
        "train_loader = DataLoader(splittrain, batch_size=25,num_workers = 2, shuffle=True)\n",
        "\n",
        "validationset = datasets.SUN397(\"/content/drive/MyDrive/Data\", download=False, transform=transform)\n",
        "splitvalidation = torch.utils.data.random_split(validationset, [val_size, len(trainset) - val_size])[0]\n",
        "val_loader = DataLoader(splitvalidation, batch_size=25,num_workers = 2, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "Y8A6H-QXgPB1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in train_loader:\n",
        "  labels = np.array(image)\n",
        "  numpy_labels = label.numpy()\n",
        "  print(labels)\n",
        "  break\n"
      ],
      "metadata": {
        "id": "9Nl3k0FUhYnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "MWIwS2W3zneL",
        "outputId": "b2119347-ce5c-4eea-e96c-fd510a7a2a32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-25a36c4c4c90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Data'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'relative_to'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50(weights = \"DEFAULT\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "asB6MX1-h3nA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=6e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(model)"
      ],
      "metadata": {
        "id": "DJNgvZZ8jEMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch, log_interval=20):\n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Loop over each batch from the training set\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Copy data to GPU if needed\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # Zero gradient buffers\n",
        "        optimizer.zero_grad() \n",
        "        \n",
        "        # Pass data through the network\n",
        "        output = model(data)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data.item()))"
      ],
      "metadata": {
        "id": "wtEkhWCgjpdk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def validate(loss_vector, accuracy_vector):\n",
        "    model.eval()\n",
        "    val_loss, correct = 0, 0\n",
        "    for data, target in val_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        output = model(data)\n",
        "        val_loss += criterion(output, target).data.item()\n",
        "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data).cpu().sum()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    loss_vector.append(val_loss)\n",
        "\n",
        "    print(pred)\n",
        "\n",
        "    accuracy = 100. * correct.to(torch.float32) / len(val_loader.dataset)\n",
        "    accuracy_vector.append(accuracy)\n",
        "\n",
        "    \n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        val_loss, correct, len(val_loader.dataset), accuracy))"
      ],
      "metadata": {
        "id": "x2ZG8LeZkE7l"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Predic(loss_vector,accuracy_vector):\n",
        "    val_loss, correct = 0, 0\n",
        "    for data, target in val_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        output = model(data)\n",
        "        val_loss += criterion(output, target).data.item()\n",
        "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data).cpu().sum()\n",
        "    print( pred)\n",
        "    print(\"/n\")\n",
        "    print(correct)\n"
      ],
      "metadata": {
        "id": "oZRKf6xM7345"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lossv, accv = [], []\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train(epoch)\n",
        "    validate(lossv, accv)\n",
        "    Predic(lossv,accv)"
      ],
      "metadata": {
        "id": "QM4rL51ekBW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e6daf9a-6f0b-49f6-e3f5-a62b1b4286fe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/5000 (0%)]\tLoss: 0.012440\n",
            "Train Epoch: 1 [500/5000 (10%)]\tLoss: 0.007685\n",
            "Train Epoch: 1 [1000/5000 (20%)]\tLoss: 0.029098\n",
            "Train Epoch: 1 [1500/5000 (30%)]\tLoss: 0.010422\n",
            "Train Epoch: 1 [2000/5000 (40%)]\tLoss: 0.054140\n",
            "Train Epoch: 1 [2500/5000 (50%)]\tLoss: 0.033673\n",
            "Train Epoch: 1 [3000/5000 (60%)]\tLoss: 0.008233\n",
            "Train Epoch: 1 [3500/5000 (70%)]\tLoss: 0.014845\n",
            "Train Epoch: 1 [4000/5000 (80%)]\tLoss: 0.009939\n",
            "Train Epoch: 1 [4500/5000 (90%)]\tLoss: 0.017391\n",
            "\n",
            "Validation set: Average loss: 2.7626, Accuracy: 214/500 (43%)\n",
            "\n",
            "tensor([158, 227, 227, 259, 107,  14, 213, 127, 263,  47, 115, 279, 270,  72,\n",
            "        133, 234, 359, 336, 358, 331, 327, 342, 228,  43,  43],\n",
            "       device='cuda:0')\n",
            "/n\n",
            "tensor(214)\n",
            "Train Epoch: 2 [0/5000 (0%)]\tLoss: 0.005537\n",
            "Train Epoch: 2 [500/5000 (10%)]\tLoss: 0.006034\n",
            "Train Epoch: 2 [1000/5000 (20%)]\tLoss: 0.010377\n",
            "Train Epoch: 2 [1500/5000 (30%)]\tLoss: 0.011989\n",
            "Train Epoch: 2 [2000/5000 (40%)]\tLoss: 0.003165\n",
            "Train Epoch: 2 [2500/5000 (50%)]\tLoss: 0.004887\n",
            "Train Epoch: 2 [3000/5000 (60%)]\tLoss: 0.007749\n",
            "Train Epoch: 2 [3500/5000 (70%)]\tLoss: 0.039206\n",
            "Train Epoch: 2 [4000/5000 (80%)]\tLoss: 0.008733\n",
            "Train Epoch: 2 [4500/5000 (90%)]\tLoss: 0.019846\n",
            "\n",
            "Validation set: Average loss: 2.7990, Accuracy: 222/500 (44%)\n",
            "\n",
            "tensor([  9, 146, 270,  63, 218, 108, 277,   6, 227, 133, 264, 101, 334,  95,\n",
            "        320,  10, 188,  75, 317, 300,  27, 277,  82, 343, 259],\n",
            "       device='cuda:0')\n",
            "/n\n",
            "tensor(222)\n",
            "Train Epoch: 3 [0/5000 (0%)]\tLoss: 0.008763\n",
            "Train Epoch: 3 [500/5000 (10%)]\tLoss: 0.003183\n",
            "Train Epoch: 3 [1000/5000 (20%)]\tLoss: 0.010987\n",
            "Train Epoch: 3 [1500/5000 (30%)]\tLoss: 0.004465\n",
            "Train Epoch: 3 [2000/5000 (40%)]\tLoss: 0.013795\n",
            "Train Epoch: 3 [2500/5000 (50%)]\tLoss: 0.019012\n",
            "Train Epoch: 3 [3000/5000 (60%)]\tLoss: 0.007612\n",
            "Train Epoch: 3 [3500/5000 (70%)]\tLoss: 0.008381\n",
            "Train Epoch: 3 [4000/5000 (80%)]\tLoss: 0.003967\n",
            "Train Epoch: 3 [4500/5000 (90%)]\tLoss: 0.008638\n",
            "\n",
            "Validation set: Average loss: 2.8279, Accuracy: 224/500 (45%)\n",
            "\n",
            "tensor([174, 227, 383, 200, 107, 268, 227, 217, 268, 132, 336, 105,  88, 213,\n",
            "          0, 295,  47, 213,  42, 326,  41, 174, 236, 184,  39],\n",
            "       device='cuda:0')\n",
            "/n\n",
            "tensor(224)\n",
            "Train Epoch: 4 [0/5000 (0%)]\tLoss: 0.006123\n",
            "Train Epoch: 4 [500/5000 (10%)]\tLoss: 0.012152\n",
            "Train Epoch: 4 [1000/5000 (20%)]\tLoss: 0.008814\n",
            "Train Epoch: 4 [1500/5000 (30%)]\tLoss: 0.007179\n",
            "Train Epoch: 4 [2000/5000 (40%)]\tLoss: 0.007694\n",
            "Train Epoch: 4 [2500/5000 (50%)]\tLoss: 0.005787\n",
            "Train Epoch: 4 [3000/5000 (60%)]\tLoss: 0.004945\n",
            "Train Epoch: 4 [3500/5000 (70%)]\tLoss: 0.005225\n",
            "Train Epoch: 4 [4000/5000 (80%)]\tLoss: 0.015980\n",
            "Train Epoch: 4 [4500/5000 (90%)]\tLoss: 0.025498\n",
            "\n",
            "Validation set: Average loss: 2.8580, Accuracy: 222/500 (44%)\n",
            "\n",
            "tensor([244,   2,  22, 198,  56,  48, 218, 274, 262, 133, 234, 122, 342, 375,\n",
            "        204, 294, 145, 358, 193,  97, 244,  95,  34,  95,  79],\n",
            "       device='cuda:0')\n",
            "/n\n",
            "tensor(222)\n",
            "Train Epoch: 5 [0/5000 (0%)]\tLoss: 0.009018\n",
            "Train Epoch: 5 [500/5000 (10%)]\tLoss: 0.006902\n",
            "Train Epoch: 5 [1000/5000 (20%)]\tLoss: 0.005880\n",
            "Train Epoch: 5 [1500/5000 (30%)]\tLoss: 0.003171\n",
            "Train Epoch: 5 [2000/5000 (40%)]\tLoss: 0.007282\n",
            "Train Epoch: 5 [2500/5000 (50%)]\tLoss: 0.013147\n",
            "Train Epoch: 5 [3000/5000 (60%)]\tLoss: 0.007785\n",
            "Train Epoch: 5 [3500/5000 (70%)]\tLoss: 0.003488\n",
            "Train Epoch: 5 [4000/5000 (80%)]\tLoss: 0.011101\n",
            "Train Epoch: 5 [4500/5000 (90%)]\tLoss: 0.010186\n",
            "\n",
            "Validation set: Average loss: 2.8865, Accuracy: 218/500 (44%)\n",
            "\n",
            "tensor([118,  41, 396,  56, 170, 291, 342,  41, 184, 232, 340, 108,  99, 294,\n",
            "          2, 326, 136, 184, 245,  25, 227,   8, 331, 133,  26],\n",
            "       device='cuda:0')\n",
            "/n\n",
            "tensor(218)\n",
            "Train Epoch: 6 [0/5000 (0%)]\tLoss: 0.024818\n",
            "Train Epoch: 6 [500/5000 (10%)]\tLoss: 0.018322\n",
            "Train Epoch: 6 [1000/5000 (20%)]\tLoss: 0.014255\n",
            "Train Epoch: 6 [1500/5000 (30%)]\tLoss: 0.049015\n",
            "Train Epoch: 6 [2000/5000 (40%)]\tLoss: 0.019656\n",
            "Train Epoch: 6 [2500/5000 (50%)]\tLoss: 0.010860\n",
            "Train Epoch: 6 [3000/5000 (60%)]\tLoss: 0.029821\n",
            "Train Epoch: 6 [3500/5000 (70%)]\tLoss: 0.005017\n",
            "Train Epoch: 6 [4000/5000 (80%)]\tLoss: 0.007797\n",
            "Train Epoch: 6 [4500/5000 (90%)]\tLoss: 0.010722\n",
            "\n",
            "Validation set: Average loss: 2.8378, Accuracy: 224/500 (45%)\n",
            "\n",
            "tensor([196,  64, 280,  87, 118, 227, 317,  86, 228, 100, 380, 296, 118, 263,\n",
            "        110, 375, 270, 279, 174, 334,  43, 286, 268, 276, 244],\n",
            "       device='cuda:0')\n",
            "/n\n",
            "tensor(224)\n",
            "Train Epoch: 7 [0/5000 (0%)]\tLoss: 0.009937\n",
            "Train Epoch: 7 [500/5000 (10%)]\tLoss: 0.006548\n",
            "Train Epoch: 7 [1000/5000 (20%)]\tLoss: 0.002907\n",
            "Train Epoch: 7 [1500/5000 (30%)]\tLoss: 0.050238\n",
            "Train Epoch: 7 [2000/5000 (40%)]\tLoss: 0.008631\n",
            "Train Epoch: 7 [2500/5000 (50%)]\tLoss: 0.018870\n",
            "Train Epoch: 7 [3000/5000 (60%)]\tLoss: 0.012887\n",
            "Train Epoch: 7 [3500/5000 (70%)]\tLoss: 0.023362\n",
            "Train Epoch: 7 [4000/5000 (80%)]\tLoss: 0.012514\n",
            "Train Epoch: 7 [4500/5000 (90%)]\tLoss: 0.089182\n",
            "\n",
            "Validation set: Average loss: 2.9398, Accuracy: 212/500 (42%)\n",
            "\n",
            "tensor([387, 108, 161,  26,  69, 313, 261,  41,  21,  67, 133,   8, 242,  25,\n",
            "        268, 326, 183, 213,  99, 193, 359, 234, 359,  59, 213],\n",
            "       device='cuda:0')\n",
            "/n\n",
            "tensor(212)\n",
            "Train Epoch: 8 [0/5000 (0%)]\tLoss: 0.007687\n",
            "Train Epoch: 8 [500/5000 (10%)]\tLoss: 0.014428\n",
            "Train Epoch: 8 [1000/5000 (20%)]\tLoss: 0.007953\n",
            "Train Epoch: 8 [1500/5000 (30%)]\tLoss: 0.010378\n",
            "Train Epoch: 8 [2000/5000 (40%)]\tLoss: 0.011439\n",
            "Train Epoch: 8 [2500/5000 (50%)]\tLoss: 0.037237\n",
            "Train Epoch: 8 [3000/5000 (60%)]\tLoss: 0.012477\n",
            "Train Epoch: 8 [3500/5000 (70%)]\tLoss: 0.030264\n",
            "Train Epoch: 8 [4000/5000 (80%)]\tLoss: 0.016965\n",
            "Train Epoch: 8 [4500/5000 (90%)]\tLoss: 0.018548\n",
            "\n",
            "Validation set: Average loss: 3.0212, Accuracy: 210/500 (42%)\n",
            "\n",
            "tensor([355, 227,  98,  41, 227, 373,  84, 146, 161, 213, 227, 331, 342, 260,\n",
            "        302,  92,  85, 174,  97, 300, 236, 350, 109, 313,  63],\n",
            "       device='cuda:0')\n",
            "/n\n",
            "tensor(210)\n",
            "Train Epoch: 9 [0/5000 (0%)]\tLoss: 0.008806\n",
            "Train Epoch: 9 [500/5000 (10%)]\tLoss: 0.030837\n",
            "Train Epoch: 9 [1000/5000 (20%)]\tLoss: 0.009303\n",
            "Train Epoch: 9 [1500/5000 (30%)]\tLoss: 0.051287\n",
            "Train Epoch: 9 [2000/5000 (40%)]\tLoss: 0.019487\n",
            "Train Epoch: 9 [2500/5000 (50%)]\tLoss: 0.015918\n",
            "Train Epoch: 9 [3000/5000 (60%)]\tLoss: 0.004803\n",
            "Train Epoch: 9 [3500/5000 (70%)]\tLoss: 0.005369\n",
            "Train Epoch: 9 [4000/5000 (80%)]\tLoss: 0.006483\n",
            "Train Epoch: 9 [4500/5000 (90%)]\tLoss: 0.008644\n",
            "\n",
            "Validation set: Average loss: 2.8810, Accuracy: 221/500 (44%)\n",
            "\n",
            "tensor([337, 102, 234, 387, 249, 179, 277,   3, 192, 115, 156,  46, 108, 184,\n",
            "        375, 227,  56, 276, 244,   8,  92, 152, 256, 337,  48],\n",
            "       device='cuda:0')\n",
            "/n\n",
            "tensor(221)\n",
            "Train Epoch: 10 [0/5000 (0%)]\tLoss: 0.009216\n",
            "Train Epoch: 10 [500/5000 (10%)]\tLoss: 0.007399\n",
            "Train Epoch: 10 [1000/5000 (20%)]\tLoss: 0.015573\n",
            "Train Epoch: 10 [1500/5000 (30%)]\tLoss: 0.007438\n",
            "Train Epoch: 10 [2000/5000 (40%)]\tLoss: 0.022248\n",
            "Train Epoch: 10 [2500/5000 (50%)]\tLoss: 0.005531\n",
            "Train Epoch: 10 [3000/5000 (60%)]\tLoss: 0.024064\n",
            "Train Epoch: 10 [3500/5000 (70%)]\tLoss: 0.006058\n",
            "Train Epoch: 10 [4000/5000 (80%)]\tLoss: 0.017513\n",
            "Train Epoch: 10 [4500/5000 (90%)]\tLoss: 0.032323\n",
            "\n",
            "Validation set: Average loss: 2.9269, Accuracy: 221/500 (44%)\n",
            "\n",
            "tensor([355, 326, 331, 337, 227, 258, 324,  76, 113,  26,  70, 302,  73, 242,\n",
            "        113, 331,  15, 335,  87,   8, 264, 110,  94, 216,  11],\n",
            "       device='cuda:0')\n",
            "/n\n",
            "tensor(221)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "metadata": {
        "id": "QrXaIvelqQ7j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}