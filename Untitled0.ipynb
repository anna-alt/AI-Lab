{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPc9MmSx7RCebN1yvrZjRvN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anna-alt/AI-Lab/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "X6EjCX3RNv7S",
        "outputId": "b95dc7fc-6326-4d52-cc8c-e18ef243c0fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "precompute_adjacency_images\n",
            "tensor([[ 0.2680, -0.0819, -0.1678, -0.1910,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000],\n",
            "        [-0.0819,  0.1756, -0.0975, -0.1714, -0.1919,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000],\n",
            "        [-0.1678, -0.0975,  0.1522, -0.1016, -0.1723, -0.1922,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000],\n",
            "        [-0.1910, -0.1714, -0.1016,  0.1460, -0.1025, -0.1725, -0.1923,  0.0000,\n",
            "          0.0000,  0.0000],\n",
            "        [ 0.0000, -0.1919, -0.1723, -0.1025,  0.1460, -0.1025, -0.1725, -0.1923,\n",
            "          0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000, -0.1922, -0.1725, -0.1025,  0.1460, -0.1025, -0.1725,\n",
            "         -0.1923,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000, -0.1923, -0.1725, -0.1025,  0.1460, -0.1025,\n",
            "         -0.1725, -0.1923],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000, -0.1923, -0.1725, -0.1025,  0.1460,\n",
            "         -0.1025, -0.1725],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1923, -0.1725, -0.1025,\n",
            "          0.1460, -0.1025],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1923, -0.1725,\n",
            "         -0.1025,  0.1460]])\n",
            "number of trainable parameters: 10240\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-7f3060ab3e78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-7f3060ab3e78>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;31m# Cross entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-7f3060ab3e78>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_edge_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjacency_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (784 x 784) --> predicted edge map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         avg_neighbor_features = (torch.bmm(self.A.unsqueeze(0).expand(B, -1, -1), \n\u001b[0m\u001b[1;32m     45\u001b[0m                                             x.view(B, -1, 1)).view(B, -1)) # (64 X 784)\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_neighbor_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [64, 1024] but got: [64, 3072]."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "\n",
        "class GraphNet(nn.Module):\n",
        "    def __init__(self, image_size = 32, pred_edge = False):\n",
        "        super(GraphNet, self).__init__()\n",
        "        self.pred_edge = pred_edge\n",
        "        N = image_size ** 2 # Number of pixels in the image\n",
        "        self.fc = nn.Linear(N, 10, bias = False)\n",
        "        # Create the adjacency matrix of size (N X N)\n",
        "        if pred_edge:\n",
        "            # Learn the adjacency matrix (learn to predict the edge between any pair of pixels)\n",
        "            col, row = np.meshgrid(np.arange(image_size), np.arange(image_size)) # (28 x 28) Explanation: https://www.geeksforgeeks.org/numpy-meshgrid-function/\n",
        "            coord = np.stack((col, row), axis = 2).reshape(-1, 2)  # (784 x 2)\n",
        "            coord_normalized = (coord - np.mean(coord, axis = 0)) / (np.std(coord, axis = 0) + 1e-5) # Normalize the matrix\n",
        "            coord_normalized = torch.from_numpy(coord_normalized).float() # (784 x 2)\n",
        "            adjacency_matrix = torch.cat((coord_normalized.unsqueeze(0).repeat(N, 1,  1),\n",
        "                                    coord_normalized.unsqueeze(1).repeat(1, N, 1)), dim=2) # (784 x 784 x 4)\n",
        "            self.pred_edge_fc = nn.Sequential(nn.Linear(4, 64),\n",
        "                                              nn.ReLU(), \n",
        "                                              nn.Linear(64, 1),\n",
        "                                              nn.Tanh())\n",
        "            self.register_buffer('adjacency_matrix', adjacency_matrix) # not to be considered a model paramater that is updated during training\n",
        "        else:\n",
        "            # Use a pre-computed adjacency matrix\n",
        "            A = self.precompute_adjacency_images(image_size)\n",
        "            self.register_buffer('A', A) # not to be considered a model paramater that is updated during training\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        x: image (batch_size x 1 x image_width x image_height)\n",
        "        '''\n",
        "        B = x.size(0) # 64\n",
        "        if self.pred_edge:\n",
        "            self.A = self.pred_edge_fc(self.adjacency_matrix).squeeze() # (784 x 784) --> predicted edge map\n",
        "\n",
        "        avg_neighbor_features = (torch.bmm(self.A.unsqueeze(0).expand(B, -1, -1), \n",
        "                                            x.view(B, -1, 1)).view(B, -1)) # (64 X 784)\n",
        "        return self.fc(avg_neighbor_features)\n",
        "\n",
        "    @staticmethod\n",
        "    # Static method knows nothing about the class and just deals with the parameters.\n",
        "    def precompute_adjacency_images(image_size):\n",
        "        print('precompute_adjacency_images')\n",
        "        col, row = np.meshgrid(np.arange(image_size), np.arange(image_size)) # (28 x 28) Explanation: https://www.geeksforgeeks.org/numpy-meshgrid-function/\n",
        "        coord = np.stack((col, row), axis = 2).reshape(-1, 2) / image_size # (784 x 2) --> normalize\n",
        "        dist = cdist(coord, coord) # compute distance between every pair of pixels\n",
        "        sigma = 0.05 * np.pi # width of the Gaussian (can be a hyperparameter while training a model)\n",
        "        A = np.exp(-dist / sigma ** 2) # adjacency matrix of spatial similarity\n",
        "        A[A < 0.01] = 0 # suppress values less than 0.01\n",
        "        A = torch.from_numpy(A).float()\n",
        "\n",
        "        # Normalization as per (Kipf & Welling, ICLR 2017)\n",
        "        D = A.sum(1)  # nodes degree (N,)\n",
        "        D_hat = (D + 1e-5) ** (-0.5)\n",
        "        A_hat = D_hat.view(-1, 1) * A * D_hat.view(1, -1)  # N,N\n",
        "\n",
        "        # Some additional trick I found to be useful\n",
        "        A_hat[A_hat > 0.0001] = A_hat[A_hat > 0.0001] - 0.2\n",
        "\n",
        "        print(A_hat[:10, :10])\n",
        "        return A_hat\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=64, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10('../data', train=False, transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])),\n",
        "    batch_size=64, shuffle=False, **kwargs)     \n",
        "    \n",
        "model = GraphNet()\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.01, weight_decay = 1e-4)\n",
        "\n",
        "print('number of trainable parameters: %d' %\n",
        "      np.sum([np.prod(p.size()) if p.requires_grad else 0 for p in model.parameters()]))\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        # Cross entropy loss\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 1000 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            \n",
        "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(\n",
        "        '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_loader.dataset),\n",
        "            100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    \n",
        "\n",
        "for epoch in range(1, 10 + 1):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lKt77WJtZFRD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}